#!/usr/bin/python

__version__ = "2.0"

__usage__ = """%prog reponame"""


import os , sys


import repolib


import optparse

def option_parser () :
    version_string = "%%prog %s" % __version__
    parser = optparse.OptionParser( usage=__usage__ , version=version_string )
    return parser


def main () :

    parser = option_parser()
    opts , args = parser.parse_args()

    if not args or len(args) > 1 :
        parser.print_help()
        sys.exit(1)

    repo_name = args.pop()

    try :
        repo = repolib.MirrorRepository.new( repo_name )
    except Exception , ex :
        print "Exception : %s" % ex
        sys.exit(255)

    if not os.path.isdir( repo.destdir ) :
        print "Destination directory '%s' does not exits" % repo.destdir
        sys.exit(2)

    return repo


def do_1st ( repo ) :

  meta_files = repo.get_metafile()

  if meta_files.values().count( False ) == len(meta_files) :
    repolib.logger.critical( "No valid metadata files found, exiting" )
    sys.exit(255)

  if meta_files.get('') is True :
    repolib.logger.info( "Updated repository, no processing required" )
    sys.exit(0)

  # After verify all the mirroring parameters, it is safe to create directory tree
  repo.build_local_tree()
  
  # Once created, we move in the primary metadata file
  local_repodata = repo.write_master_file( meta_files )
  
  repolib.logger.setLevel( repolib.logging.INFO )
  map( repolib.logger.info , repo.info( local_repodata ).split("\n") )

  return local_repodata


def do_2nd ( repo , local_repodata ) :

  download_pkgs = repo.get_download_list()
  download_size = 0
  missing_pkgs = []

  for subrepo in repo.subrepos :

    packages = subrepo.get_metafile( local_repodata )

    if packages is True :
        continue

    repolib.logger.info( "Scanning %s" % ( subrepo , ) )

    _size , _pkgs , _missing = subrepo.get_package_list( packages , {} , repo.filters )
    download_size += _size
    download_pkgs.queue( _pkgs )
    missing_pkgs.extend( _missing )

  _size = download_size / 1024 / 1024
  if _size > 2048 :
    repolib.logger.info( "Total size to download : %.1f Gb" % ( _size / 1024 ) )
  else :
    repolib.logger.info( "Total size to download : %.1f Mb" % _size )

  return download_pkgs , missing_pkgs


repo = main()
local_repodata = do_1st( repo )
download_pkgs , missing_pkgs = do_2nd( repo , local_repodata )

if missing_pkgs :

    _missing = {}
    for pkg in missing_pkgs :
        _missing[ pkg ] = 1

    found_pkgs = {}
    for pkg in download_pkgs :
        # NOTE : We don't break the loop to ensure we get all the available archs
        if pkg['name'] in _missing.keys() :
            # repolib.logger.info( "FOUND %s" % pkg['name'] )
            found_pkgs[ pkg['name'] ] = pkg
    # NOTE : extending here is safer
    download_pkgs.queue( found_pkgs.values() )

    missing = []
    for pkg in _missing.keys() :
        if not pkg in found_pkgs.keys() :
            missing.append( pkg )
    if missing :
        repolib.logger.warning( "There are %d missing requirements : %s " % ( len(missing) , missing[:5] ) )

download_pkgs.start()
download_pkgs.finish()

